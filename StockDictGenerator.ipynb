{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "C8AS73ha2zWj"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Function to load selected acronyms from the DataFrame\n",
        "def load_acronyms_from_csv(csv_file):\n",
        "    # Load the CSV into a pandas DataFrame\n",
        "    acronyms_df = pd.read_csv(csv_file)\n",
        "\n",
        "    # Get the unique list of acronyms (assuming 'Acronym' is the correct column name)\n",
        "    acronyms = acronyms_df['Acronym'].unique()\n",
        "    return acronyms\n",
        "\n",
        "# Function to compute correlation matrix and create a heatmap, and save it as a PDF\n",
        "def plot_correlation_heatmap(df, acronyms, output_pdf_path):\n",
        "    # Select only the columns corresponding to the acronyms\n",
        "    selected_data = df[acronyms]\n",
        "\n",
        "    # Compute the correlation matrix\n",
        "    correlation_matrix = selected_data.corr()\n",
        "\n",
        "    # Increase the figure size to avoid truncation\n",
        "    plt.figure(figsize=(14, 12))  # Adjust size as needed\n",
        "\n",
        "    # Plot heatmap using seaborn with larger size and adjust other settings\n",
        "    sns.heatmap(correlation_matrix, annot=False, cmap='coolwarm', linewidths=0.5,\n",
        "                cbar_kws={'shrink': 0.8})  # Shrink color bar for better fit\n",
        "\n",
        "    # Add title to the heatmap\n",
        "    plt.title('Correlation Heatmap of Metrics', fontsize=16)\n",
        "\n",
        "    # Adjust layout to fit everything\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Save the plot as a PDF\n",
        "    plt.savefig(output_pdf_path, format='pdf')\n",
        "\n",
        "    # Close the plot to free memory\n",
        "    plt.close()\n",
        "\n",
        "# Main function to run the analysis\n",
        "def analyze_metrics_correlation(df, csv_file, output_pdf_path):\n",
        "    # Load acronyms from the CSV\n",
        "    acronyms = load_acronyms_from_csv(csv_file)\n",
        "\n",
        "    # Plot the heatmap for correlated metrics and save it as a PDF\n",
        "    plot_correlation_heatmap(df, acronyms, output_pdf_path)\n",
        "\n",
        "# Example usage:\n",
        "df = pd.read_csv('/content/hackathon_sample_v2.csv')  # Replace with your actual DataFrame source\n",
        "csv_file = '/content/metrics_acronyms.csv'  # Replace with your CSV file path\n",
        "output_pdf_path = '/content/heatmap_output.pdf'  # Replace with the desired PDF output path\n",
        "\n",
        "# Run the analysis and save the heatmap\n",
        "analyze_metrics_correlation(df, csv_file, output_pdf_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "class StockDataProcessor:\n",
        "    \"\"\"\n",
        "    StockDataProcessor class provides methods to load acronyms from a CSV file, create a filtered DataFrame,\n",
        "    filter stock tickers based on continuous months of data, and save the results to a JSON file.\n",
        "\n",
        "    Attributes:\n",
        "    -----------\n",
        "    csv_file : str\n",
        "        Path to the CSV file containing acronyms.\n",
        "    df : pd.DataFrame\n",
        "        DataFrame containing the stock data.\n",
        "    additional_columns : list\n",
        "        List of additional columns to keep from the original DataFrame.\n",
        "    acronyms : list\n",
        "        List of unique acronyms loaded from the CSV file.\n",
        "    acronyms_df : pd.DataFrame\n",
        "        Filtered DataFrame containing only the acronyms and additional columns.\n",
        "\n",
        "    Methods:\n",
        "    --------\n",
        "    load_acronyms_from_csv():\n",
        "        Loads acronyms from the provided CSV file.\n",
        "\n",
        "    create_acronyms_dataframe():\n",
        "        Creates a new DataFrame that includes only the acronyms and additional columns.\n",
        "\n",
        "    filter_tickers_by_continuous_months(min_months=12):\n",
        "        Filters the DataFrame for stock tickers that have at least `min_months` continuous months of data.\n",
        "\n",
        "    save_dict_to_json(data, file_path):\n",
        "        Saves the filtered ticker data to a JSON file in a human-readable format.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, csv_file, df, additional_columns):\n",
        "        \"\"\"\n",
        "        Initializes the StockDataProcessor with the CSV file, DataFrame, and additional columns.\n",
        "\n",
        "        Parameters:\n",
        "        -----------\n",
        "        csv_file : str\n",
        "            Path to the CSV file containing the acronyms.\n",
        "        df : pd.DataFrame\n",
        "            The full dataset that includes stock ticker data and associated metrics.\n",
        "        additional_columns : list\n",
        "            List of additional columns to keep from the original DataFrame (e.g., 'stock_ticker', 'year', 'month').\n",
        "\n",
        "        Raises:\n",
        "        -------\n",
        "        ValueError : if the csv_file or additional_columns are invalid.\n",
        "        \"\"\"\n",
        "        if not csv_file or not isinstance(csv_file, str):\n",
        "            raise ValueError(\"Invalid CSV file path provided.\")\n",
        "        if not isinstance(additional_columns, list):\n",
        "            raise ValueError(\"additional_columns should be a list.\")\n",
        "\n",
        "        self.csv_file = csv_file\n",
        "        self.df = df\n",
        "        self.additional_columns = additional_columns\n",
        "        self.acronyms = self.load_acronyms_from_csv()\n",
        "        self.acronyms_df = self.create_acronyms_dataframe()\n",
        "\n",
        "    def load_acronyms_from_csv(self):\n",
        "        \"\"\"\n",
        "        Loads unique acronyms from the provided CSV file.\n",
        "\n",
        "        Returns:\n",
        "        --------\n",
        "        list:\n",
        "            A list of unique acronyms found in the CSV file under the 'Acronym' column.\n",
        "\n",
        "        Raises:\n",
        "        -------\n",
        "        FileNotFoundError : if the CSV file cannot be found.\n",
        "        KeyError : if the 'Acronym' column is missing from the CSV file.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            acronyms_df = pd.read_csv(self.csv_file)\n",
        "        except FileNotFoundError:\n",
        "            raise FileNotFoundError(f\"The file {self.csv_file} does not exist.\")\n",
        "\n",
        "        if 'Acronym' not in acronyms_df.columns:\n",
        "            raise KeyError(\"The CSV file must contain an 'Acronym' column.\")\n",
        "\n",
        "        acronyms = acronyms_df['Acronym'].unique()\n",
        "        return acronyms\n",
        "\n",
        "    def create_acronyms_dataframe(self):\n",
        "        \"\"\"\n",
        "        Creates a new DataFrame that contains only the selected acronyms and additional columns.\n",
        "\n",
        "        Returns:\n",
        "        --------\n",
        "        pd.DataFrame:\n",
        "            A filtered DataFrame with acronyms and additional columns such as 'stock_ticker', 'year', 'month'.\n",
        "\n",
        "        Raises:\n",
        "        -------\n",
        "        KeyError : if any of the required columns are missing from the DataFrame.\n",
        "        \"\"\"\n",
        "        columns_to_keep = list(self.acronyms) + self.additional_columns\n",
        "        missing_columns = [col for col in columns_to_keep if col not in self.df.columns]\n",
        "\n",
        "        if missing_columns:\n",
        "            raise KeyError(f\"The following columns are missing from the DataFrame: {missing_columns}\")\n",
        "\n",
        "        acronyms_df = self.df[columns_to_keep]\n",
        "        return acronyms_df\n",
        "\n",
        "    def filter_tickers_by_continuous_months(self, min_months=12):\n",
        "        \"\"\"\n",
        "        Filters the DataFrame for stock tickers that have at least `min_months` continuous months of data.\n",
        "\n",
        "        Parameters:\n",
        "        -----------\n",
        "        min_months : int, optional\n",
        "            Minimum number of continuous months required (default is 12).\n",
        "\n",
        "        Returns:\n",
        "        --------\n",
        "        dict:\n",
        "            A dictionary of stock tickers with continuous month data, where the keys are stock tickers, years,\n",
        "            and months, and the values are dictionaries containing the rest of the columns.\n",
        "\n",
        "        Example:\n",
        "        --------\n",
        "        {\n",
        "            'AAPL': {\n",
        "                2021: {\n",
        "                    1: {'feature1': 123, 'feature2': 456},\n",
        "                    2: {'feature1': 789, 'feature2': 101}\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "\n",
        "        Raises:\n",
        "        -------\n",
        "        ValueError : if the DataFrame does not contain required columns ('stock_ticker', 'year', 'month').\n",
        "        \"\"\"\n",
        "        # Ensure required columns are present\n",
        "        required_columns = ['stock_ticker', 'year', 'month']\n",
        "        if not all(col in self.acronyms_df.columns for col in required_columns):\n",
        "            raise ValueError(f\"The DataFrame must contain the following columns: {required_columns}\")\n",
        "\n",
        "        # Sort the dataframe by stock_ticker, year, and month to ensure it's ordered correctly.\n",
        "        self.acronyms_df = self.acronyms_df.sort_values(by=required_columns)\n",
        "\n",
        "        # Group by stock_ticker\n",
        "        grouped = self.acronyms_df.groupby('stock_ticker')\n",
        "\n",
        "        # Create a dictionary to hold the filtered tickers\n",
        "        filtered_tickers = {}\n",
        "\n",
        "        # Iterate over each group (each stock ticker)\n",
        "        for ticker, group in grouped:\n",
        "            # Reset the index to ensure continuity in month checking\n",
        "            group = group.reset_index(drop=True)\n",
        "\n",
        "            # Create a 'date' column for each row based on year and month\n",
        "            group['date'] = pd.to_datetime(group[['year', 'month']].assign(day=1))\n",
        "\n",
        "            # Calculate the difference in months between consecutive rows\n",
        "            group['month_diff'] = group['date'].diff().dt.days // 30\n",
        "\n",
        "            # Replace the first value with 1 to handle the NaN generated by diff\n",
        "            group['month_diff'].fillna(1, inplace=True)\n",
        "\n",
        "            # Check if there are at least `min_months` continuous months\n",
        "            current_streak = 0\n",
        "            start_index = None\n",
        "            for i, diff in enumerate(group['month_diff']):\n",
        "                if diff == 1:  # Continuous month\n",
        "                    if current_streak == 0:\n",
        "                        start_index = i\n",
        "                    current_streak += 1\n",
        "                else:\n",
        "                    current_streak = 1  # Reset the streak if discontinuous\n",
        "                    start_index = i  # Start a new streak\n",
        "\n",
        "                # If streak is at least `min_months`, process the data\n",
        "                if current_streak >= min_months:\n",
        "                    # Construct the nested dictionary for this ticker\n",
        "                    for _, row in group.iloc[start_index:start_index + min_months].iterrows():\n",
        "                        year = row['year']\n",
        "                        month = row['month']\n",
        "\n",
        "                        # Create a dictionary of the rest of the columns excluding stock_ticker, year, and month\n",
        "                        rest_of_columns = row.drop(['stock_ticker', 'year', 'month', 'date', 'month_diff']).to_dict()\n",
        "\n",
        "                        # Initialize the structure if not already present\n",
        "                        if ticker not in filtered_tickers:\n",
        "                            filtered_tickers[ticker] = {}\n",
        "                        if year not in filtered_tickers[ticker]:\n",
        "                            filtered_tickers[ticker][year] = {}\n",
        "\n",
        "                        # Add the month data\n",
        "                        filtered_tickers[ticker][year][month] = rest_of_columns\n",
        "\n",
        "                    break  # Stop after finding the first valid sequence\n",
        "\n",
        "        return filtered_tickers\n",
        "\n",
        "    def save_dict_to_json(self, data, file_path):\n",
        "        \"\"\"\n",
        "        Saves the filtered ticker data to a JSON file in a human-readable format.\n",
        "\n",
        "        Parameters:\n",
        "        -----------\n",
        "        data : dict\n",
        "            The dictionary to save.\n",
        "        file_path : str\n",
        "            The file path where the JSON data will be saved.\n",
        "\n",
        "        Raises:\n",
        "        -------\n",
        "        ValueError : if the file path is not a valid string.\n",
        "        \"\"\"\n",
        "        if not isinstance(file_path, str):\n",
        "            raise ValueError(\"Invalid file path provided.\")\n",
        "\n",
        "        with open(file_path, 'w') as json_file:\n",
        "            json.dump(data, json_file, indent=4)  # indent=4 makes the file human-readable\n",
        "\n",
        "\n",
        "# Example usage:\n",
        "if __name__ == \"__main__\":\n",
        "    # Load your stock dataset\n",
        "    df = pd.read_csv('/content/hackathon_sample_v2.csv')  # Your actual DataFrame source\n",
        "    csv_file = '/content/metrics_acronyms.csv'  # CSV file containing acronyms\n",
        "    additional_columns = ['stock_ticker', 'year', 'month']\n",
        "\n",
        "    # Instantiate the class\n",
        "    processor = StockDataProcessor(csv_file, df, additional_columns)\n",
        "\n",
        "    # Filter tickers by continuous months\n",
        "    ticker_dict = processor.filter_tickers_by_continuous_months(min_months=12)\n",
        "\n",
        "    # Save the result as JSON\n",
        "    processor.save_dict_to_json(ticker_dict, 'new_stocks_dict.json')\n"
      ],
      "metadata": {
        "id": "wx-2hSLl-3yk"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hndKHycmAOx4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}